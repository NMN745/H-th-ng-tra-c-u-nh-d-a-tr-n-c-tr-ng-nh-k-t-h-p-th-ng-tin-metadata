import os
import faiss
import torch
import numpy as np
import requests
from datetime import datetime
from torchvision import models, transforms
from flask import Flask, request, render_template, send_from_directory, jsonify
from PIL import Image
import shutil
import tempfile

# ============================
# Config
# ============================
UNSPLASH_ACCESS_KEY = "g2YPsiwAcq4xa3-zLthhXlA-3NF4u7KeCT_IqXwNJqY"  # Thay b·∫±ng key th·∫≠t
TEMP_FOLDER = "temp_images"
LOCAL_IMAGE_FOLDER = "images"
os.makedirs(TEMP_FOLDER, exist_ok=True)
os.makedirs(LOCAL_IMAGE_FOLDER, exist_ok=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üîß Device: {device}")

# ============================
# 1. Model ResNet18 (C·∫£i thi·ªán error handling)
# ============================
model = models.resnet18(weights="IMAGENET1K_V1")
model = torch.nn.Sequential(*list(model.children())[:-1])
model.eval().to(device)

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

def extract_feature(img_path):
    try:
        # Test open PIL tr∆∞·ªõc
        with Image.open(img_path) as img_pil:
            img = img_pil.convert("RGB")  # Force RGB ƒë·ªÉ tr√°nh format issue
            print(f"   ‚úÖ PIL open OK: {img_path} (size: {img.size})")
        img_tensor = transform(img).unsqueeze(0).to(device)
        with torch.no_grad():
            feat = model(img_tensor).squeeze().cpu().numpy()
        feat = feat / np.linalg.norm(feat)
        print(f"   ‚úÖ Extract feature OK: {img_path}")
        return feat
    except Exception as e:
        print(f"   ‚ùå Extract fail {img_path}: {e}")
        return None

# ============================
# 2. Load local DB (Th√™m debug)
# ============================
def load_local_db():
    image_paths = [os.path.join(LOCAL_IMAGE_FOLDER, f) for f in os.listdir(LOCAL_IMAGE_FOLDER)
                   if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
    
    features = []
    metadata_db = {}
    print("üîç Load local DB...")
    print(f"   Local paths: {[os.path.basename(p) for p in image_paths]}")
    
    for idx, path in enumerate(image_paths):
        vec = extract_feature(path)
        if vec is not None:
            features.append(vec)
            metadata_db[idx] = {
                "filename": os.path.basename(path),
                "year": 2023 if idx % 2 == 0 else 2024,
                "author": "Local User",
                "description": "·∫¢nh local",
                "tags": "local",
                "location": "N/A",
                "created_at": "2024-01-01",
                "download_url": f"/images/{os.path.basename(path)}"
            }
    
    if features:
        features = np.array(features).astype("float32")
        d = features.shape[1]
        index = faiss.IndexFlatL2(d)
        index.add(features)
        print(f"‚úÖ Local DB: {len(features)} ·∫£nh loaded.")
        return index, metadata_db
    else:
        print("‚ö† Local DB r·ªóng (th√™m ·∫£nh v√†o images/).")
        d = 512
        index = faiss.IndexFlatL2(d)
        return index, {}

# ============================
# 3. Unsplash API (C·∫£i thi·ªán: Debug + partial success)
# ============================
def search_unsplash(query, per_page=5):
    if not UNSPLASH_ACCESS_KEY or UNSPLASH_ACCESS_KEY == "YOUR_UNSPLASH_ACCESS_KEY_HERE":
        print("‚ö† No API key, skip Unsplash.")
        return None, {}, []
    
    url = "https://api.unsplash.com/search/photos"
    headers = {"Authorization": f"Client-ID {UNSPLASH_ACCESS_KEY}"}
    params = {"query": query, "per_page": per_page, "orientation": "squarish"}
    
    try:
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        results = data.get("results", [])
        print(f"üì° Unsplash API: {len(results)} photos found.")
        
        features = []
        metadata_db = {}
        downloaded_paths = []
        
        print(f"‚¨áÔ∏è Downloading & extracting {len(results)} images...")
        for idx, photo in enumerate(results):
            try:
                created_at = photo.get("created_at", "")
                year = int(datetime.fromisoformat(created_at).year) if created_at else 2023
                user = photo.get("user", {})
                author = user.get("name", "Unknown")
                description = photo.get("description", "") or photo.get("alt_description", "")
                tags = [keyword["slug"] for keyword in photo.get("tags", [])[:3]]
                location = photo.get("location", {}).get("title", "N/A") if photo.get("location") else "N/A"
                download_url = photo["urls"]["small"]
                
                # Download
                print(f"   Downloading {idx+1}: {photo['id']}")
                img_response = requests.get(download_url, stream=True)
                img_response.raise_for_status()
                filename = f"{photo['id']}.jpg"
                img_path = os.path.join(TEMP_FOLDER, filename)
                with open(img_path, "wb") as f:
                    for chunk in img_response.iter_content(chunk_size=8192):
                        f.write(chunk)
                
                # Check file
                if os.path.exists(img_path) and os.path.getsize(img_path) > 1000:
                    downloaded_paths.append(img_path)
                    print(f"   üìÅ Saved: {filename} (size: {os.path.getsize(img_path)} bytes)")
                    
                    # Extract (c√≥ th·ªÉ fail)
                    vec = extract_feature(img_path)
                    if vec is not None:
                        features.append(vec)
                        metadata_db[idx] = {
                            "filename": filename,
                            "year": year,
                            "author": author,
                            "description": description,
                            "tags": ", ".join(tags),
                            "location": location,
                            "created_at": created_at,
                            "download_url": photo["urls"]["full"]
                        }
                        print(f"   ‚úÖ Processed: {filename}")
                    else:
                        print(f"   ‚ö† Skipped extract: {filename} (keep metadata for keyword search)")
                        # V·∫™N TH√äM METADATA ƒê·ªÇ D√ôNG CHO KEYWORD SEARCH (FIX BUG)
                        metadata_db[idx] = {
                            "filename": filename,
                            "year": year,
                            "author": author,
                            "description": description,
                            "tags": ", ".join(tags),
                            "location": location,
                            "created_at": created_at,
                            "download_url": photo["urls"]["full"]
                        }
                else:
                    print(f"   ‚ùå Download fail: {filename}")
                    if os.path.exists(img_path):
                        os.remove(img_path)
            except Exception as e:
                print(f"   ‚ùå Error {idx}: {e}")
        
        # Build index n·∫øu c√≥ features (c√≥ th·ªÉ partial)
        if features:
            features = np.array(features).astype("float32")
            d = features.shape[1]
            index = faiss.IndexFlatL2(d)
            index.add(features)
            print(f"‚úÖ Unsplash index: {len(features)}/{len(results)} processed.")
            return index, metadata_db, downloaded_paths
        else:
            print("‚ö† No features extracted, but metadata available for keyword search.")
            # Return dummy index n·∫øu ch·ªâ keyword search (kh√¥ng upload)
            d = 512
            index = faiss.IndexFlatL2(d)
            return index, metadata_db, downloaded_paths  # FIX: Return metadata d√π no features
    except Exception as e:
        print(f"‚ùå Unsplash API error: {e}")
        return None, {}, []

# ============================
# 4. Flask App
# ============================
app = Flask(__name__)

# Global
current_index = None
current_metadata = {}
current_paths = []
use_unsplash = False

@app.route("/", methods=["GET", "POST"])
def home():
    global current_index, current_metadata, current_paths, use_unsplash
    
    error = None
    if request.method == "POST":
        keyword = request.form.get("keyword", "").strip()
        if not keyword:
            error = "‚ö† Vui l√≤ng nh·∫≠p t·ª´ kh√≥a!"
            return render_template("index.html", error=error)
        
        # Clear temp
        if os.path.exists(TEMP_FOLDER):
            shutil.rmtree(TEMP_FOLDER)
        os.makedirs(TEMP_FOLDER, exist_ok=True)
        
        # Th·ª≠ Unsplash
        print("üöÄ Starting search for:", keyword)
        current_index, current_metadata, current_paths = search_unsplash(keyword)
        
        # FIX LOGIC: N·∫øu c√≥ metadata t·ª´ Unsplash (d√π index partial), d√πng Unsplash mode
        if current_metadata:  # Priority: N·∫øu c√≥ data t·ª´ Unsplash
            use_unsplash = True
            print(f"‚úÖ Use Unsplash mode: {len(current_metadata)} items")
        elif current_index is None:  # Fallback ch·ªâ n·∫øu ho√†n to√†n fail
            current_index, current_metadata = load_local_db()
            use_unsplash = False
            print("üîÑ Fallback to local.")
        else:
            use_unsplash = True  # N·∫øu index OK
        
        print(f"üìä Final: Use Unsplash={use_unsplash}, Metadata keys={[k for k in current_metadata.keys()][:3]}...")  # Debug filenames
        
        if not current_metadata:
            error = "‚ö† Kh√¥ng c√≥ d·ªØ li·ªáu (th√™m ·∫£nh v√†o images/ ho·∫∑c ki·ªÉm tra API key)."
            return render_template("index.html", error=error)
        
        # Upload query (gi·ªØ nguy√™n + debug t·ª´ tr∆∞·ªõc)
        file = request.files.get("file")
        query_filename = None
        if file and file.filename != "":
            if not file.content_type or not file.content_type.startswith('image/'):
                error = "‚ö† File kh√¥ng ph·∫£i ·∫£nh!"
                return render_template("index.html", error=error)
            
            timestamp = int(datetime.now().timestamp())
            query_filename = f"query_{timestamp}.jpg"
            query_path = os.path.join(TEMP_FOLDER, query_filename)
            try:
                file.save(query_path)
                if os.path.exists(query_path) and os.path.getsize(query_path) > 100:
                    print(f"‚úÖ Query saved: {query_path} (size: {os.path.getsize(query_path)})")
                else:
                    raise Exception("File r·ªóng")
            except Exception as e:
                print(f"‚ùå Query save error: {e}")
                error = "‚ö† L·ªói l∆∞u ·∫£nh query!"
                return render_template("index.html", error=error)
            
            # Search similar (ch·ªâ n·∫øu index c√≥ data)
            if current_index.ntotal > 0:
                qvec = extract_feature(query_path)
                if qvec is not None:
                    qvec = qvec.astype("float32").reshape(1, -1)
                    k = min(5, current_index.ntotal)
                    D, I = current_index.search(qvec, k)
                    
                    results = []
                    for dist, idx in zip(D[0], I[0]):
                        if idx < len(current_metadata):
                            meta = current_metadata[idx]
                            similarity = round((1 / (1 + dist)) * 100, 2)
                            meta_score = round(100 if keyword.lower() in meta.get("tags", "").lower() else 50, 2)
                            results.append({**meta, "similarity": similarity, "meta_score": meta_score})
                    results = sorted(results, key=lambda x: x["similarity"] + x["meta_score"], reverse=True)[:5]
                else:
                    results = []  # No search if query fail
            else:
                results = list(current_metadata.values())[:5]  # Fallback top
                for r in results:
                    r["similarity"] = 0
                    r["meta_score"] = 100
            return render_template("results.html", query=query_filename, results=results, keyword=keyword, use_unsplash=use_unsplash)
        
        else:
            # No upload: Top results
            results = list(current_metadata.values())[:5]
            for r in results:
                r["similarity"] = 0
                r["meta_score"] = 100
            return render_template("results.html", query=None, results=results, keyword=keyword, use_unsplash=use_unsplash)
    
    return render_template("index.html", error=error)

@app.route("/images/<filename>")
def images_static(filename):
    full_path = os.path.join(LOCAL_IMAGE_FOLDER, filename)
    print(f"üîç Local serve: {full_path} (exist: {os.path.exists(full_path)})")
    if os.path.exists(full_path):
        return send_from_directory(LOCAL_IMAGE_FOLDER, filename)
    return "Not found", 404

@app.route("/temp_images/<filename>")
def temp_images_static(filename):
    full_path = os.path.join(TEMP_FOLDER, filename)
    print(f"üîç Temp serve: {full_path} (exist: {os.path.exists(full_path)})")
    if os.path.exists(full_path):
        return send_from_directory(TEMP_FOLDER, filename)
    return "Not found", 404

@app.route("/cleanup")
def cleanup():
    global current_paths
    for path in current_paths:
        if os.path.exists(path):
            os.remove(path)
    current_paths = []
    if os.path.exists(TEMP_FOLDER):
        shutil.rmtree(TEMP_FOLDER)
    return "Cleaned!"

if __name__ == "__main__":
    app.run(debug=True, host='0.0.0.0', port=5000)